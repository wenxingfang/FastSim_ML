#include "NNPred.h"
#include <torch/script.h> // One-stop header.
#include <ATen/Parallel.h> // One-stop header.
#include <iostream>
#include <memory>

double gaussrand()
{
    static double V1, V2, S;
    static int phase = 0;
    double X;
     
    if ( phase == 0 ) {
        do {
            double U1 = (double)rand() / RAND_MAX;
            double U2 = (double)rand() / RAND_MAX;
             
            V1 = 2 * U1 - 1;
            V2 = 2 * U2 - 1;
            S = V1 * V1 + V2 * V2;
        } while(S >= 1 || S == 0);
         
        X = V1 * sqrt(-2 * log(S) / S);
    } else
        X = V2 * sqrt(-2 * log(S) / S);
         
    phase = 1 - phase;
 
    return X;
}

struct Magic {
    Magic(){
        module = torch::jit::load("/hpcfs/juno/junogpu/fangwx/FastSim/JUNO/job_sub/pyTorch_job/old/my_module_model.pt");
           }
    torch::jit::script::Module module;
};


NNPred::NNPred(char s_model[])
//NNPred::NNPred()
{
  m_name = std::string(s_model);
  std::cout <<"model name="<<m_name<<std::endl;
 /*// the m_magic still has run time error
  try {
      m_magic = new Magic() ;
      }
  catch (...) {
        throw "error loading the model";
              }
  std::cout << "ok\n";
  */
}

NNPred::~NNPred()
{
}



std::vector<float>* NNPred::get(int type, float r, const std::vector<float>& v_theta, float scale)//r from 0-20 m, theta from 0-pi
{

//static torch::Device device_CPU(torch::kCPU);
//static torch::Device device_CUDA(torch::kCUDA);

//  at::init_num_threads(); // not good
auto options = torch::TensorOptions().dtype(torch::kFloat32);
int N_size = v_theta.size();
std::vector<torch::jit::IValue> inputs;
std::vector<at::Tensor> inputs_vec;
std::vector<float*> vec_arr;
for(unsigned int i=0; i < N_size; i++)
{
    //float in_array[] = {r/20, (v_theta.at(i)*180/3.1415926535898)/180, gaussrand()};
    float* in_array = new float[3];// need use new to allcoate memory 
    in_array[0]=r/20;
    in_array[1]=(v_theta.at(i)*180/3.1415926535898)/180;
    //in_array[2]=gaussrand();
    in_array[2]=0.5;
    //std::cout <<"i="<<i<<",r="<<in_array[0]<<",theta="<<in_array[1]<<",noise="<<in_array[2] << std::endl;
    torch::Tensor tharray = torch::from_blob(in_array, {3}, options);
    inputs_vec.push_back(tharray);
    vec_arr.push_back(in_array);
}
//at::Tensor input_ = torch::cat(inputs_vec);// not new dim
at::Tensor input_ = torch::stack(inputs_vec);// new dim
inputs.push_back(input_);
//std::cout <<"input_ dim()"<<input_.dim()<<",itemsize()="<<input_.itemsize()<<",is_mkldnn="<<input_.is_mkldnn()<<","<< '\n';
//input_.print();
//std::cout <<"tensor="<< input_ << std::endl;

at::Tensor output;
if(type==1)
{   static torch::jit::script::Module   module_1 = torch::jit::load(m_name);
    output = module_1.forward(inputs).toTensor()*scale;
}
else if(type==2) 
{
    static torch::jit::script::Module   module_2 = torch::jit::load(m_name);
    output = module_2.forward(inputs).toTensor()*scale;
}
else if(type==3) 
{
    static torch::jit::script::Module   module_3 = torch::jit::load(m_name);
    output = module_3.forward(inputs).toTensor()*scale;
}
else 
{
    static torch::jit::script::Module   module_4 = torch::jit::load(m_name);
    output = module_4.forward(inputs).toTensor()*scale;
}
std::vector<float>* v = new std::vector<float>( output.data<float>(), output.data<float>() + output.numel() );
//std::vector<float> v(output.data<float>(), output.data<float>() + output.numel());
for(unsigned i=0; i < v->size(); i++){std::cout<<"i="<<i<<",v(i)="<<v->at(i)<<std::endl;}
for(unsigned i=0; i<vec_arr.size(); i++) delete [] vec_arr.at(i);
return v;
}
